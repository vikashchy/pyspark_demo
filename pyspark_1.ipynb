{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "public-brunswick",
   "metadata": {},
   "source": [
    "### Import pyspark & create  a session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-activation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('localhost').getOrCreate() # To create a session on standalone pyspark cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-causing",
   "metadata": {},
   "source": [
    "#### read the data in spark session, format of type csv , header (to make first row as header) and load the original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = spark.read.format('csv').option(\"header\", \"true\").load(\"original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-davis",
   "metadata": {},
   "source": [
    "#### show the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-recipe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydata.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-simpson",
   "metadata": {},
   "source": [
    "#### Show the datatypes of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "least-sculpture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('first_name', 'string'),\n",
       " ('last_name', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('City', 'string'),\n",
       " ('JobTitle', 'string'),\n",
       " ('Salary', 'string'),\n",
       " ('Latitude', 'string'),\n",
       " ('Longitude', 'string')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-syntax",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-whale",
   "metadata": {},
   "source": [
    "##### add a new column and add a criteria to check if the data is null, provide a default value otherwise the city value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-methodology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydata2= mydata.withColumn(\"clean_city\",when(mydata.City.isNull(),'Unknown').otherwise(mydata.City))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-edward",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydata2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-antigua",
   "metadata": {},
   "source": [
    "#### Filter the column where job titile is not null & replace the existing df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-cuisine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydata2 = mydata2.filter(mydata2.JobTitle.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-arizona",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydata2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-validation",
   "metadata": {},
   "source": [
    "#### Create  a new dataframe, add a column, take substing & cast it to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-industry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salary_data=mydata2.withColumn(\"clean_salary\",mydata2.Salary.substr(2,100).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-appraisal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salary_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-enough",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean=salary_data.groupBy().avg('clean_salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-monitor",
   "metadata": {},
   "source": [
    "##### take the mean salary from filterred column & slice it to get the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-chick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean=salary_data.groupBy().avg('clean_salary').take(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-karaoke",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-little",
   "metadata": {},
   "source": [
    "#####  select latitute col, filter the values which are not null , add a new col in df & cast the values to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-constraint",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lats=salary_data.select('Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-dimension",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lats=lats.filter(lats.Latitude.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-daughter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lats = lats.withColumn('Lat_new',lats.Latitude.cast('float')).select('Lat_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-portrait",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median= np.median(lats.collect())\n",
    "print(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-bookmark",
   "metadata": {},
   "source": [
    "#### take the literal value of median and replace it in new col if the lat is null else take the original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-culture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salary_data = salary_data.withColumn('lat', when(salary_data.Latitude.isNull(), lit(median)).otherwise(salary_data.Latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-lambda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salary_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-playing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sqlfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-triangle",
   "metadata": {},
   "source": [
    "##### Group by gender taking the aggregated value of the avg salary from cleaned salary col , alias to provide a new col to agg salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-scout",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genders=salary_data.groupBy('gender').agg(sqlfunc.avg('clean_salary').alias('AvgSalary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-longer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-tackle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salary_data= salary_data.withColumn('female_salary',when(salary_data.gender=='Female',salary_data.clean_salary).otherwise(lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-consultancy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "salary_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-instrumentation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salary_data= salary_data.withColumn('male_salary',when(salary_data.gender=='Male',salary_data.clean_salary).otherwise(lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-plastic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agg_df=salary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df=agg_df.groupBy('JobTitle').agg(sqlfunc.avg('female_salary').alias('female_salary_aggregated'), sqlfunc.avg('male_salary').alias('male_salary_aggregated'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df=agg_df.withColumn('Delta', agg_df.female_salary_aggregated - agg_df.male_salary_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_avg_salary=salary_data.groupBy('City').agg(sqlfunc.avg(salary_data.clean_salary).alias('avg_salary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_avg_salary=city_avg_salary.sort(col('avg_salary').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_avg_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-decline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
